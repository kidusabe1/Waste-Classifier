{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T00:50:25.903763Z",
     "start_time": "2024-12-02T00:50:25.898805Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T00:50:26.912536Z",
     "start_time": "2024-12-02T00:50:26.906325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "8c9c34d0812109d5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:50:43.189900Z",
     "start_time": "2024-12-02T01:50:42.392808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = YOLO(model=\"/home/202490517/waste-classifier/runs/classify/train17/weights/best.pt\") \n",
    "\n",
    "results = model.val(data=\"/home/202490517/waste-classifier/data.yaml\", split=\"test\", plots=True)"
   ],
   "id": "a4a9a508e9395377",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No images or videos found in /home/202490517/waste-classifier/data.yaml. Supported formats are:\nimages: {'jpg', 'jpeg', 'tif', 'png', 'heic', 'pfm', 'tiff', 'webp', 'mpo', 'dng', 'bmp'}\nvideos: {'avi', 'mp4', 'gif', 'mov', 'ts', 'm4v', 'asf', 'mpg', 'mpeg', 'webm', 'mkv', 'wmv'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/202490517/waste-classifier/runs/classify/train17/weights/best.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m) \n\u001B[0;32m----> 3\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(source\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/202490517/waste-classifier/data.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, plots\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/engine/model.py:554\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, source, stream, predictor, **kwargs)\u001B[0m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset_prompts\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mset_prompts(prompts)\n\u001B[0;32m--> 554\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mpredict_cli(source\u001B[38;5;241m=\u001B[39msource) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor(source\u001B[38;5;241m=\u001B[39msource, stream\u001B[38;5;241m=\u001B[39mstream)\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/engine/predictor.py:169\u001B[0m, in \u001B[0;36mBasePredictor.__call__\u001B[0;34m(self, source, model, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/torch/utils/_contextlib.py:36\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 36\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     40\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/engine/predictor.py:227\u001B[0m, in \u001B[0;36mBasePredictor.stream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msetup_model(model)\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:  \u001B[38;5;66;03m# for thread-safe inference\u001B[39;00m\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;66;03m# Setup source every time predict is called\u001B[39;00m\n\u001B[0;32m--> 227\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msetup_source(source \u001B[38;5;28;01mif\u001B[39;00m source \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msource)\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# Check if save_dir/ label file exists\u001B[39;00m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msave \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msave_txt:\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/engine/predictor.py:199\u001B[0m, in \u001B[0;36mBasePredictor.setup_source\u001B[0;34m(self, source)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgsz \u001B[38;5;241m=\u001B[39m check_imgsz(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mimgsz, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mstride, min_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# check image size\u001B[39;00m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28mgetattr\u001B[39m(\n\u001B[1;32m    192\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    198\u001B[0m )\n\u001B[0;32m--> 199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m load_inference_source(\n\u001B[1;32m    200\u001B[0m     source\u001B[38;5;241m=\u001B[39msource,\n\u001B[1;32m    201\u001B[0m     batch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mbatch,\n\u001B[1;32m    202\u001B[0m     vid_stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mvid_stride,\n\u001B[1;32m    203\u001B[0m     buffer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mstream_buffer,\n\u001B[1;32m    204\u001B[0m )\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39msource_type\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_type\u001B[38;5;241m.\u001B[39mstream\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_type\u001B[38;5;241m.\u001B[39mscreenshot\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1000\u001B[39m  \u001B[38;5;66;03m# many images\u001B[39;00m\n\u001B[1;32m    210\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvideo_flag\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;28;01mFalse\u001B[39;00m]))\n\u001B[1;32m    211\u001B[0m ):  \u001B[38;5;66;03m# videos\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/data/build.py:202\u001B[0m, in \u001B[0;36mload_inference_source\u001B[0;34m(source, batch, vid_stride, buffer)\u001B[0m\n\u001B[1;32m    200\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m LoadPilAndNumpy(source)\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 202\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m LoadImagesAndVideos(source, batch\u001B[38;5;241m=\u001B[39mbatch, vid_stride\u001B[38;5;241m=\u001B[39mvid_stride)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;66;03m# Attach source types to the dataset\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28msetattr\u001B[39m(dataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource_type\u001B[39m\u001B[38;5;124m\"\u001B[39m, source_type)\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/data/loaders.py:365\u001B[0m, in \u001B[0;36mLoadImagesAndVideos.__init__\u001B[0;34m(self, path, batch, vid_stride)\u001B[0m\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnf \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo images or videos found in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFORMATS_HELP_MSG\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: No images or videos found in /home/202490517/waste-classifier/data.yaml. Supported formats are:\nimages: {'jpg', 'jpeg', 'tif', 'png', 'heic', 'pfm', 'tiff', 'webp', 'mpo', 'dng', 'bmp'}\nvideos: {'avi', 'mp4', 'gif', 'mov', 'ts', 'm4v', 'asf', 'mpg', 'mpeg', 'webm', 'mkv', 'wmv'}"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:24:51.067523Z",
     "start_time": "2024-12-02T01:24:51.060975Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "5d081da2522b652b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f7c08a01e90>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9208443462848663\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8434476852416992, 'metrics/accuracy_top5': 0.9982410073280334, 'fitness': 0.9208443462848663}\n",
       "save_dir: PosixPath('runs/classify/val7')\n",
       "speed: {'preprocess': 0.7457714282113832, 'inference': 16.672929966774756, 'loss': 0.0007815180688755703, 'postprocess': 0.0006376700959084007}\n",
       "task: 'classify'\n",
       "top1: 0.8434476852416992\n",
       "top5: 0.9982410073280334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:26:19.409466Z",
     "start_time": "2024-12-02T01:26:19.373222Z"
    }
   },
   "cell_type": "code",
   "source": "print(results.box.map)",
   "id": "fb1a6ce2b8433123",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClassifyMetrics' object has no attribute 'box'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (Dict[str, float]): A dictionary containing the time taken for each step in the pipeline.\n        fitness (float): The fitness of the model, which is equal to top-5 accuracy.\n        results_dict (Dict[str, Union[float, str]]): A dictionary containing the classification metrics and fitness.\n        keys (List[str]): A list of keys for the results_dict.\n\n    Methods:\n        process(targets, pred): Processes the targets and predictions to compute classification metrics.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(results\u001B[38;5;241m.\u001B[39mbox\u001B[38;5;241m.\u001B[39mmap)\n",
      "File \u001B[0;32m~/.conda/envs/Waste_classifier/lib/python3.11/site-packages/ultralytics/utils/__init__.py:221\u001B[0m, in \u001B[0;36mSimpleClass.__getattr__\u001B[0;34m(self, attr)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001B[39;00m\n\u001B[1;32m    220\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. See valid attributes below.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__doc__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ClassifyMetrics' object has no attribute 'box'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (Dict[str, float]): A dictionary containing the time taken for each step in the pipeline.\n        fitness (float): The fitness of the model, which is equal to top-5 accuracy.\n        results_dict (Dict[str, Union[float, str]]): A dictionary containing the classification metrics and fitness.\n        keys (List[str]): A list of keys for the results_dict.\n\n    Methods:\n        process(targets, pred): Processes the targets and predictions to compute classification metrics.\n    "
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d104d0562401cfc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
